{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yewexSls1gmT",
        "outputId": "e1879d45-91a7-4f38-cbe6-acced3bb312d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wiU60mr_z2YS"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder , OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/project/try.csv')"
      ],
      "metadata": {
        "id": "XEyTB7c7CCbu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0ut9k0Y6-c-H"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#簡單的\n",
        "x, y = df[df.columns[2:]], df[df.columns[1]]\n",
        "labelencoder = LabelEncoder()\n",
        "y = labelencoder.fit_transform(y)\n",
        "\n",
        "x_traval, x_test, y_traval, y_test = train_test_split(x, y, test_size=0.2, random_state = 1, stratify= y)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_traval, y_traval, test_size=0.2, random_state = 1, stratify= y_traval)\n",
        "\n"
      ],
      "metadata": {
        "id": "5pKugkmGAwrX"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QRZ4XOHC-imT"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reshape\n",
        "x_train_r = np.array(x_train).reshape(-1,100,100)\n",
        "x_test_r = np.array(x_test).reshape(-1,100,100)\n",
        "x_val_r = np.array(x_val).reshape(-1,100,100)\n",
        "\n",
        "# y_train = np.array(y_train)\n",
        "# y_test = np.array(y_test)\n",
        "# y_val = np.array(y_val)\n",
        "\n",
        "# 轉換色彩 0~255 資料為 0~1\n",
        "x_train_r = x_train_r.astype('float32')\n",
        "x_val_r = x_val_r.astype('float32')\n",
        "x_test_r = x_test_r.astype('float32')\n",
        "\n",
        "x_train_r /= 255\n",
        "x_val_r /= 255\n",
        "x_test_r /= 255\n",
        "\n",
        "# y 值轉成 one-hot encoding\n",
        "y_train_e = keras.utils.to_categorical(y_train, num_classes=8, dtype='float32') \n",
        "y_test_e = keras.utils.to_categorical(y_test, num_classes=8, dtype='float32')\n",
        "y_val_e = keras.utils.to_categorical(y_val, num_classes=8, dtype='float32')\n",
        "\n",
        "# mnist 的圖集黑色是255，白色是 0，而圖片讀進來是 黑色是0，白色是 255\n",
        "# 所以在這裡除255後，也順便把黑白翻轉過來。\n",
        "#data = 1 - data / 255.0 已經做了uint8"
      ],
      "metadata": {
        "id": "j8QFnLNRbnAr"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPZAwY-Qz2Yg"
      },
      "outputs": [],
      "source": [
        "# from keras.preprocessing.image import ImageDataGenerator #利用現有的資料經過旋轉、翻轉、縮放…等方式增加更多的訓練資料\n",
        "# train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
        "# test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "\n",
        "# #要把資料做轉換的步驟則是用 .flow(X,y) 或是 .flow_from_directory(directory) 讀取資料集+批量生成器，產生每epoch訓練樣本\n",
        "# training_set = train_datagen.flow_from_directory(\"./classify/dataset/training_set\", target_size = (64, 64), batch_size = 5)\n",
        "# test_set = test_datagen.flow_from_directory(\"./classify/dataset/test_set\", target_size = (64, 64), batch_size = 5)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 定義分類數量 每個系列\n",
        "num_classes = 8\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(100, 100, 1), activation='relu')) #32 is no. of filters and kernel size is 3*3. ReLU is activation layer\n",
        "# model.add(MaxPooling2D(pool_size=(2,2))) #add Max pooling layer with kernel size 2*2 \n",
        "# model.add(Dropout(0.3))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu')) \n",
        "# model.add(MaxPooling2D(pool_size=(2,2))) \n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# model.add(Dropout(0.3))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# model.add(Dropout(0.4))\n",
        "# model.add(Conv2D(512, (3, 3), activation='relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2,2))) \n",
        "model.add(Flatten())\n",
        "# model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax')) \n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "model.fit(x_train_r, y_train_e, validation_data=(x_val_r, y_val_e), epochs=20, batch_size=16)\n",
        "\n",
        "#Evaluating model in keras\n",
        "score = model.evaluate(x_test_r, y_test_e, verbose=0)\n",
        "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
        "\n",
        "# model.fit_generator(training_set, epochs = 2, validation_data = test_set, verbose = 1)\n",
        "# score = model.evaluate_generator(test_set)\n",
        "\n",
        "#model.save('my_model.h5', include_optimizer=False)\n",
        "#如果你對這個模型滿意，想要保留之後使用的話，可以這樣設定儲存參數，那麼優化器的狀態不會被保存下來，可以節省不少體積，減少的體積量依使用優化器的不同而定，使用adam的話，這麼做是很有感的，如果你是之前中斷訓練，且有意後續載入繼續進行訓練的話，建議可以先不做。"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYJqmq5jPLZd",
        "outputId": "d70a1b67-7bc9-41c2-9eae-a91aa574ee45"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "13/13 [==============================] - 43s 3s/step - loss: 4.0175 - acc: 0.2010 - val_loss: 2.0011 - val_acc: 0.2885\n",
            "Epoch 2/20\n",
            "13/13 [==============================] - 59s 5s/step - loss: 1.9533 - acc: 0.3039 - val_loss: 1.9073 - val_acc: 0.2885\n",
            "Epoch 3/20\n",
            "13/13 [==============================] - 41s 3s/step - loss: 1.9035 - acc: 0.3039 - val_loss: 1.9011 - val_acc: 0.2885\n",
            "Epoch 4/20\n",
            "13/13 [==============================] - 43s 3s/step - loss: 1.8884 - acc: 0.3039 - val_loss: 1.9093 - val_acc: 0.2885\n",
            "Epoch 5/20\n",
            "13/13 [==============================] - 41s 3s/step - loss: 1.8501 - acc: 0.3039 - val_loss: 1.8786 - val_acc: 0.2885\n",
            "Epoch 6/20\n",
            "13/13 [==============================] - 41s 3s/step - loss: 1.7305 - acc: 0.3480 - val_loss: 1.8610 - val_acc: 0.3269\n",
            "Epoch 7/20\n",
            "13/13 [==============================] - 41s 3s/step - loss: 1.4003 - acc: 0.5294 - val_loss: 2.0188 - val_acc: 0.3846\n",
            "Epoch 8/20\n",
            "13/13 [==============================] - 41s 3s/step - loss: 0.9722 - acc: 0.6765 - val_loss: 2.1712 - val_acc: 0.4231\n",
            "Epoch 9/20\n",
            "13/13 [==============================] - 43s 3s/step - loss: 0.6979 - acc: 0.7402 - val_loss: 2.3942 - val_acc: 0.4231\n",
            "Epoch 10/20\n",
            "13/13 [==============================] - 41s 3s/step - loss: 0.8165 - acc: 0.7500 - val_loss: 2.4266 - val_acc: 0.5000\n",
            "Epoch 11/20\n",
            "13/13 [==============================] - 41s 3s/step - loss: 0.5528 - acc: 0.8235 - val_loss: 3.3358 - val_acc: 0.5577\n",
            "Epoch 12/20\n",
            "13/13 [==============================] - 41s 3s/step - loss: 0.3000 - acc: 0.8971 - val_loss: 3.4933 - val_acc: 0.5385\n",
            "Epoch 13/20\n",
            "13/13 [==============================] - 41s 3s/step - loss: 0.3154 - acc: 0.8922 - val_loss: 4.5254 - val_acc: 0.5769\n",
            "Epoch 14/20\n",
            "13/13 [==============================] - 43s 3s/step - loss: 0.2244 - acc: 0.9216 - val_loss: 4.7994 - val_acc: 0.5577\n",
            "Epoch 15/20\n",
            "13/13 [==============================] - 41s 3s/step - loss: 0.1592 - acc: 0.9608 - val_loss: 5.4454 - val_acc: 0.6538\n",
            "Epoch 16/20\n",
            "13/13 [==============================] - 41s 3s/step - loss: 0.1620 - acc: 0.9510 - val_loss: 5.8767 - val_acc: 0.4808\n",
            "Epoch 17/20\n",
            "13/13 [==============================] - 41s 3s/step - loss: 0.1511 - acc: 0.9755 - val_loss: 4.8033 - val_acc: 0.7115\n",
            "Epoch 18/20\n",
            "13/13 [==============================] - 41s 3s/step - loss: 0.1705 - acc: 0.9510 - val_loss: 4.9670 - val_acc: 0.5769\n",
            "Epoch 19/20\n",
            "13/13 [==============================] - 43s 3s/step - loss: 0.1812 - acc: 0.9755 - val_loss: 3.7169 - val_acc: 0.6538\n",
            "Epoch 20/20\n",
            "13/13 [==============================] - 41s 3s/step - loss: 0.0581 - acc: 0.9951 - val_loss: 3.9313 - val_acc: 0.7115\n",
            "Test loss: 2.331758975982666 / Test accuracy: 0.609375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYHmq6WMz2Yi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e40d1799-ff3a-427a-c191-5bedcad6ff73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 19s 6s/step - loss: 3.9745 - acc: 0.0078 - val_loss: 3.9136 - val_acc: 0.0156\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 3.9306 - acc: 0.0117 - val_loss: 3.9129 - val_acc: 0.0156\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 3.9159 - acc: 0.0195 - val_loss: 3.9127 - val_acc: 0.0156\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 3.9162 - acc: 0.0176 - val_loss: 3.9134 - val_acc: 0.0312\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 3.9125 - acc: 0.0176 - val_loss: 3.9135 - val_acc: 0.0234\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 17s 5s/step - loss: 3.9135 - acc: 0.0195 - val_loss: 3.9141 - val_acc: 0.0156\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 3.9138 - acc: 0.0234 - val_loss: 3.9137 - val_acc: 0.0234\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 3.9110 - acc: 0.0254 - val_loss: 3.9134 - val_acc: 0.0156\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 3.9104 - acc: 0.0195 - val_loss: 3.9140 - val_acc: 0.0156\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 3.9099 - acc: 0.0195 - val_loss: 3.9139 - val_acc: 0.0156\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 3.9075 - acc: 0.0254 - val_loss: 3.9130 - val_acc: 0.0234\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 3.9045 - acc: 0.0117 - val_loss: 3.9126 - val_acc: 0.0234\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 3.8966 - acc: 0.0352 - val_loss: 3.9116 - val_acc: 0.0234\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 3.8851 - acc: 0.0293 - val_loss: 3.9114 - val_acc: 0.0156\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 3.8652 - acc: 0.0234 - val_loss: 3.9095 - val_acc: 0.0156\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 3.8319 - acc: 0.0176 - val_loss: 3.8954 - val_acc: 0.0078\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 3.7934 - acc: 0.0332 - val_loss: 3.8646 - val_acc: 0.0312\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 3.7724 - acc: 0.0469 - val_loss: 3.8058 - val_acc: 0.0391\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 17s 5s/step - loss: 3.6915 - acc: 0.0566 - val_loss: 3.8122 - val_acc: 0.0234\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 3.6230 - acc: 0.0723 - val_loss: 3.7799 - val_acc: 0.0312\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 3.5484 - acc: 0.0938 - val_loss: 3.7299 - val_acc: 0.0312\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 3.4655 - acc: 0.0918 - val_loss: 3.5534 - val_acc: 0.0547\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 3.2982 - acc: 0.1543 - val_loss: 3.5222 - val_acc: 0.0312\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 3.2274 - acc: 0.1250 - val_loss: 3.4865 - val_acc: 0.0859\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 3.0499 - acc: 0.1777 - val_loss: 3.1676 - val_acc: 0.1016\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 2.8825 - acc: 0.1758 - val_loss: 3.1355 - val_acc: 0.0938\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 2.6846 - acc: 0.2363 - val_loss: 2.9761 - val_acc: 0.1406\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 2.6573 - acc: 0.2070 - val_loss: 2.9299 - val_acc: 0.1406\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 2.4701 - acc: 0.2422 - val_loss: 2.9828 - val_acc: 0.1016\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 2.4268 - acc: 0.2480 - val_loss: 2.9298 - val_acc: 0.1328\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 17s 6s/step - loss: 2.1976 - acc: 0.3145 - val_loss: 2.5813 - val_acc: 0.1641\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 17s 5s/step - loss: 1.9468 - acc: 0.3926 - val_loss: 2.7905 - val_acc: 0.1875\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 16s 5s/step - loss: 1.8938 - acc: 0.3887 - val_loss: 2.6730 - val_acc: 0.1875\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 1.7018 - acc: 0.4590 - val_loss: 2.4856 - val_acc: 0.1641\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 1.7897 - acc: 0.4160 - val_loss: 2.3116 - val_acc: 0.2344\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 1.4912 - acc: 0.4922 - val_loss: 2.5276 - val_acc: 0.1641\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 1.4604 - acc: 0.5352 - val_loss: 2.2988 - val_acc: 0.2500\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 1.2867 - acc: 0.5566 - val_loss: 2.2026 - val_acc: 0.2500\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 1.3805 - acc: 0.5332 - val_loss: 2.4675 - val_acc: 0.2969\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 1.2299 - acc: 0.5977 - val_loss: 2.4403 - val_acc: 0.2109\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 1.2310 - acc: 0.5938 - val_loss: 2.4386 - val_acc: 0.2656\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 1.1371 - acc: 0.6211 - val_loss: 2.3102 - val_acc: 0.2500\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 1.0250 - acc: 0.6562 - val_loss: 2.2688 - val_acc: 0.2969\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 17s 6s/step - loss: 0.9560 - acc: 0.6719 - val_loss: 2.0048 - val_acc: 0.3750\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.8677 - acc: 0.7422 - val_loss: 2.5374 - val_acc: 0.2109\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.9317 - acc: 0.6836 - val_loss: 2.3827 - val_acc: 0.2969\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.8987 - acc: 0.6855 - val_loss: 2.0858 - val_acc: 0.3125\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.8173 - acc: 0.7324 - val_loss: 2.1588 - val_acc: 0.3047\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.7896 - acc: 0.7441 - val_loss: 2.4382 - val_acc: 0.2891\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.7463 - acc: 0.7500 - val_loss: 2.1824 - val_acc: 0.3359\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.6661 - acc: 0.7852 - val_loss: 2.1177 - val_acc: 0.3594\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.6422 - acc: 0.7891 - val_loss: 1.9379 - val_acc: 0.3750\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.5662 - acc: 0.8281 - val_loss: 2.0486 - val_acc: 0.3047\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.5534 - acc: 0.8125 - val_loss: 1.8937 - val_acc: 0.3750\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.5251 - acc: 0.8379 - val_loss: 1.9216 - val_acc: 0.3828\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.4991 - acc: 0.8398 - val_loss: 2.1746 - val_acc: 0.2969\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 17s 5s/step - loss: 0.4818 - acc: 0.8418 - val_loss: 2.0191 - val_acc: 0.3516\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.4280 - acc: 0.8613 - val_loss: 2.2611 - val_acc: 0.3516\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.4668 - acc: 0.8496 - val_loss: 2.3330 - val_acc: 0.2969\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.5032 - acc: 0.8340 - val_loss: 2.0915 - val_acc: 0.3750\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.5642 - acc: 0.8145 - val_loss: 2.4535 - val_acc: 0.2969\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.5135 - acc: 0.8379 - val_loss: 2.6088 - val_acc: 0.2188\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.5109 - acc: 0.7969 - val_loss: 2.2745 - val_acc: 0.3203\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.5140 - acc: 0.8301 - val_loss: 2.7635 - val_acc: 0.2891\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.4880 - acc: 0.8223 - val_loss: 2.3532 - val_acc: 0.3750\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.4325 - acc: 0.8613 - val_loss: 2.3403 - val_acc: 0.3047\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.4204 - acc: 0.8477 - val_loss: 2.2598 - val_acc: 0.3828\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.3897 - acc: 0.8555 - val_loss: 2.1066 - val_acc: 0.3672\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.3294 - acc: 0.8809 - val_loss: 2.1005 - val_acc: 0.3906\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 17s 5s/step - loss: 0.2927 - acc: 0.9023 - val_loss: 2.3844 - val_acc: 0.3828\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 18s 6s/step - loss: 0.2948 - acc: 0.9102 - val_loss: 2.0319 - val_acc: 0.4062\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.2860 - acc: 0.9062 - val_loss: 2.0026 - val_acc: 0.4141\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.3427 - acc: 0.8770 - val_loss: 2.0547 - val_acc: 0.4062\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.2827 - acc: 0.9121 - val_loss: 2.2273 - val_acc: 0.3672\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.2466 - acc: 0.9121 - val_loss: 2.0419 - val_acc: 0.4297\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.2591 - acc: 0.9160 - val_loss: 2.0828 - val_acc: 0.3984\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.2380 - acc: 0.9258 - val_loss: 2.1356 - val_acc: 0.4531\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.2333 - acc: 0.9316 - val_loss: 2.4515 - val_acc: 0.3359\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.2333 - acc: 0.9473 - val_loss: 1.9756 - val_acc: 0.4297\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.2100 - acc: 0.9375 - val_loss: 2.1862 - val_acc: 0.3984\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 16s 5s/step - loss: 0.2332 - acc: 0.9141 - val_loss: 2.2444 - val_acc: 0.3984\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 17s 5s/step - loss: 0.2100 - acc: 0.9297 - val_loss: 2.2455 - val_acc: 0.3672\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.2081 - acc: 0.9375 - val_loss: 2.1371 - val_acc: 0.3906\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.1778 - acc: 0.9375 - val_loss: 2.4716 - val_acc: 0.3594\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.1796 - acc: 0.9473 - val_loss: 2.2179 - val_acc: 0.4219\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 16s 5s/step - loss: 0.1679 - acc: 0.9551 - val_loss: 2.0415 - val_acc: 0.4453\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.1438 - acc: 0.9551 - val_loss: 2.0777 - val_acc: 0.4531\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 16s 5s/step - loss: 0.1560 - acc: 0.9531 - val_loss: 2.2329 - val_acc: 0.4531\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.1228 - acc: 0.9648 - val_loss: 2.0884 - val_acc: 0.3906\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.1213 - acc: 0.9688 - val_loss: 2.1690 - val_acc: 0.4219\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.1361 - acc: 0.9570 - val_loss: 2.2132 - val_acc: 0.3750\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.1151 - acc: 0.9688 - val_loss: 2.0572 - val_acc: 0.4531\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.1233 - acc: 0.9688 - val_loss: 2.0146 - val_acc: 0.4375\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 17s 6s/step - loss: 0.1086 - acc: 0.9707 - val_loss: 2.1770 - val_acc: 0.4609\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.1087 - acc: 0.9766 - val_loss: 2.1402 - val_acc: 0.3984\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.0955 - acc: 0.9766 - val_loss: 2.1261 - val_acc: 0.4531\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 16s 5s/step - loss: 0.1155 - acc: 0.9727 - val_loss: 2.1570 - val_acc: 0.4219\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.0904 - acc: 0.9824 - val_loss: 2.0188 - val_acc: 0.4688\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 16s 5s/step - loss: 0.1214 - acc: 0.9648 - val_loss: 2.4383 - val_acc: 0.3672\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.1015 - acc: 0.9668 - val_loss: 2.1204 - val_acc: 0.4453\n",
            "Test loss: 1.9123109579086304 / Test accuracy: 0.48750001192092896\n"
          ]
        }
      ],
      "source": [
        "# 定義分類數量 每雙\n",
        "num_classes = 50 \n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(100, 100, 1), activation='relu')) #32 is no. of filters and kernel size is 3*3. ReLU is activation layer\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) #add Max pooling layer with kernel size 2*2 \n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(64, (3, 3), activation='tanh')) \n",
        "model.add(MaxPooling2D(pool_size=(2,2))) \n",
        "model.add(Dropout(0.35))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(256, (3, 3), activation='tanh'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) \n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax')) \n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "model.fit(x_train_r, y_train, validation_data=(x_val_r, y_val), epochs=100, batch_size=200)\n",
        "\n",
        "#Evaluating model in keras\n",
        "score = model.evaluate(x_test_r, y_test, verbose=0)\n",
        "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
        "\n",
        "# model.fit_generator(training_set, epochs = 2, validation_data = test_set, verbose = 1)\n",
        "# score = model.evaluate_generator(test_set)\n",
        "\n",
        "#model.save('my_model.h5', include_optimizer=False)\n",
        "#如果你對這個模型滿意，想要保留之後使用的話，可以這樣設定儲存參數，那麼優化器的狀態不會被保存下來，可以節省不少體積，減少的體積量依使用優化器的不同而定，使用adam的話，這麼做是很有感的，如果你是之前中斷訓練，且有意後續載入繼續進行訓練的話，建議可以先不做。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Structure\n",
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model_{}.png'.format(timestr),show_shapes=True, show_layer_names=True)\n"
      ],
      "metadata": {
        "id": "Wrb8Ksmek-Qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Training History\n",
        "import collections\n",
        "import pandas as pd\n",
        "hist = history.history\n",
        "\n",
        "for key, val in hist.items(): # Count the number of epoch\n",
        "    numepo = len(np.asarray(val))\n",
        "    break\n",
        "hist = collections.OrderedDict(hist)\n",
        "pd.DataFrame(hist).to_excel('model_{}_history.xlsx'.format(timestr), index=True)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig('Model accuracy_{}.png'.format(timestr))\n",
        "plt.cla()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig('Model loss_{}.png'.format(timestr))\n",
        "plt.cla()"
      ],
      "metadata": {
        "id": "x7qDbgi-lHl8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "574df64408e4635801aa20724f5bd67158dcc0405c62728fda99f99539c35838"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}