{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yewexSls1gmT",
        "outputId": "9c2839b3-03e0-4f82-da33-db5d81af603e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wiU60mr_z2YS"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder , OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/project/transformation.csv')"
      ],
      "metadata": {
        "id": "XEyTB7c7CCbu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#簡單的\n",
        "x, y = df[df.columns[1:]], df[df.columns[0]]\n",
        "labelencoder = LabelEncoder()\n",
        "y = labelencoder.fit_transform(y)\n",
        "\n",
        "x_traval, x_test, y_traval, y_test = train_test_split(x, y, test_size=0.2, random_state = 1, stratify= y)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_traval, y_traval, test_size=0.2, random_state = 1, stratify= y_traval)\n",
        "\n"
      ],
      "metadata": {
        "id": "5pKugkmGAwrX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reshape\n",
        "x_train_r = np.array(x_train).reshape(-1,100,100)\n",
        "x_test_r = np.array(x_test).reshape(-1,100,100)\n",
        "x_val_r = np.array(x_val).reshape(-1,100,100)\n",
        "\n",
        "# y_train = np.array(y_train)\n",
        "# y_test = np.array(y_test)\n",
        "# y_val = np.array(y_val)\n",
        "\n",
        "# 轉換色彩 0~255 資料為 0~1\n",
        "x_train_r = x_train_r.astype('float32')\n",
        "x_val_r = x_val_r.astype('float32')\n",
        "x_test_r = x_test_r.astype('float32')\n",
        "\n",
        "x_train_r /= 255\n",
        "x_val_r /= 255\n",
        "x_test_r /= 255\n",
        "\n",
        "# y 值轉成 one-hot encoding\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes=50, dtype='float32') \n",
        "y_test = keras.utils.to_categorical(y_test, num_classes=50, dtype='float32')\n",
        "y_val = keras.utils.to_categorical(y_val, num_classes=50, dtype='float32')\n",
        "\n",
        "# mnist 的圖集黑色是255，白色是 0，而圖片讀進來是 黑色是0，白色是 255\n",
        "# 所以在這裡除255後，也順便把黑白翻轉過來。\n",
        "#data = 1 - data / 255.0 已經做了uint8"
      ],
      "metadata": {
        "id": "j8QFnLNRbnAr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#標準化 min-max https://stackoverflow.com/questions/72517783/scaling-row-wise-with-minmaxscaler-from-sklearn"
      ],
      "metadata": {
        "id": "564Mp2v08_WW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPZAwY-Qz2Yg"
      },
      "outputs": [],
      "source": [
        "# from keras.preprocessing.image import ImageDataGenerator #利用現有的資料經過旋轉、翻轉、縮放…等方式增加更多的訓練資料\n",
        "# train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
        "# test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "\n",
        "# #要把資料做轉換的步驟則是用 .flow(X,y) 或是 .flow_from_directory(directory) 讀取資料集+批量生成器，產生每epoch訓練樣本\n",
        "# training_set = train_datagen.flow_from_directory(\"./classify/dataset/training_set\", target_size = (64, 64), batch_size = 5)\n",
        "# test_set = test_datagen.flow_from_directory(\"./classify/dataset/test_set\", target_size = (64, 64), batch_size = 5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "sYHmq6WMz2Yi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2ec1d5d-f92a-43a5-f360-f676ba8ab917"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 4.0316 - acc: 0.0195 - val_loss: 3.9120 - val_acc: 0.0234\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.9270 - acc: 0.0137 - val_loss: 3.9143 - val_acc: 0.0078\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.9194 - acc: 0.0254 - val_loss: 3.9162 - val_acc: 0.0234\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.9197 - acc: 0.0137 - val_loss: 3.9176 - val_acc: 0.0156\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.9159 - acc: 0.0137 - val_loss: 3.9197 - val_acc: 0.0234\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.9137 - acc: 0.0195 - val_loss: 3.9186 - val_acc: 0.0234\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.9128 - acc: 0.0254 - val_loss: 3.9190 - val_acc: 0.0234\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.9116 - acc: 0.0234 - val_loss: 3.9210 - val_acc: 0.0156\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.9121 - acc: 0.0312 - val_loss: 3.9261 - val_acc: 0.0156\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 16s 4s/step - loss: 3.9126 - acc: 0.0293 - val_loss: 3.9284 - val_acc: 0.0156\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.9121 - acc: 0.0234 - val_loss: 3.9288 - val_acc: 0.0156\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.9103 - acc: 0.0254 - val_loss: 3.9274 - val_acc: 0.0234\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.9106 - acc: 0.0156 - val_loss: 3.9333 - val_acc: 0.0156\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.9071 - acc: 0.0234 - val_loss: 3.9271 - val_acc: 0.0312\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.9068 - acc: 0.0176 - val_loss: 3.9177 - val_acc: 0.0156\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.9035 - acc: 0.0312 - val_loss: 3.9191 - val_acc: 0.0156\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.8967 - acc: 0.0293 - val_loss: 3.9160 - val_acc: 0.0156\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.8863 - acc: 0.0293 - val_loss: 3.9247 - val_acc: 0.0156\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.8631 - acc: 0.0430 - val_loss: 3.9637 - val_acc: 0.0000e+00\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.8285 - acc: 0.0332 - val_loss: 4.0190 - val_acc: 0.0000e+00\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.8117 - acc: 0.0312 - val_loss: 3.9042 - val_acc: 0.0312\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.8434 - acc: 0.0254 - val_loss: 3.9336 - val_acc: 0.0156\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.7538 - acc: 0.0488 - val_loss: 3.9261 - val_acc: 0.0312\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 3.7367 - acc: 0.0625 - val_loss: 3.7980 - val_acc: 0.0234\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 15s 4s/step - loss: 3.6872 - acc: 0.0820 - val_loss: 4.1385 - val_acc: 0.0312\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.6149 - acc: 0.0820 - val_loss: 3.7339 - val_acc: 0.0391\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.5609 - acc: 0.0781 - val_loss: 3.9658 - val_acc: 0.0234\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.4130 - acc: 0.1289 - val_loss: 4.2902 - val_acc: 0.0234\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.3134 - acc: 0.1230 - val_loss: 4.3832 - val_acc: 0.0234\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.1296 - acc: 0.1367 - val_loss: 5.4681 - val_acc: 0.0000e+00\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.1867 - acc: 0.1367 - val_loss: 7.1076 - val_acc: 0.0156\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.2644 - acc: 0.1074 - val_loss: 3.2203 - val_acc: 0.0859\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 3.0806 - acc: 0.1387 - val_loss: 4.0509 - val_acc: 0.0547\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 2.8562 - acc: 0.1777 - val_loss: 3.1436 - val_acc: 0.0469\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 2.7004 - acc: 0.2148 - val_loss: 3.7989 - val_acc: 0.0469\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 2.4870 - acc: 0.2559 - val_loss: 3.0607 - val_acc: 0.0859\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 2.3367 - acc: 0.2734 - val_loss: 3.4368 - val_acc: 0.0781\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 2.1441 - acc: 0.3398 - val_loss: 3.9119 - val_acc: 0.0781\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 2.0792 - acc: 0.3340 - val_loss: 4.4870 - val_acc: 0.0469\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 15s 4s/step - loss: 1.9274 - acc: 0.3438 - val_loss: 3.9507 - val_acc: 0.0625\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 1.7897 - acc: 0.4102 - val_loss: 3.4197 - val_acc: 0.0938\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 1.5472 - acc: 0.4824 - val_loss: 4.7903 - val_acc: 0.0469\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 1.5783 - acc: 0.4766 - val_loss: 5.7001 - val_acc: 0.0703\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 1.4484 - acc: 0.5020 - val_loss: 5.6260 - val_acc: 0.0469\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 1.3928 - acc: 0.5410 - val_loss: 5.9648 - val_acc: 0.0469\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 1.2857 - acc: 0.5430 - val_loss: 5.2042 - val_acc: 0.0859\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 1.1702 - acc: 0.6152 - val_loss: 4.3538 - val_acc: 0.1016\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 13s 4s/step - loss: 1.1396 - acc: 0.6055 - val_loss: 4.8240 - val_acc: 0.0938\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 13s 4s/step - loss: 1.0938 - acc: 0.6309 - val_loss: 5.6781 - val_acc: 0.0703\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 1.0171 - acc: 0.6543 - val_loss: 7.3908 - val_acc: 0.0312\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.9803 - acc: 0.6602 - val_loss: 7.4517 - val_acc: 0.0391\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 13s 4s/step - loss: 0.8726 - acc: 0.6992 - val_loss: 6.4726 - val_acc: 0.0781\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 13s 4s/step - loss: 0.8860 - acc: 0.7031 - val_loss: 5.9053 - val_acc: 0.0938\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 13s 4s/step - loss: 0.7943 - acc: 0.7461 - val_loss: 5.8306 - val_acc: 0.0781\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.7970 - acc: 0.7227 - val_loss: 6.7683 - val_acc: 0.0703\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 13s 4s/step - loss: 0.7206 - acc: 0.7500 - val_loss: 7.6920 - val_acc: 0.0547\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 13s 4s/step - loss: 0.6952 - acc: 0.7891 - val_loss: 6.4522 - val_acc: 0.0781\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 13s 4s/step - loss: 0.6176 - acc: 0.7852 - val_loss: 7.8423 - val_acc: 0.0547\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 13s 4s/step - loss: 0.6267 - acc: 0.7910 - val_loss: 6.9911 - val_acc: 0.1016\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 13s 4s/step - loss: 0.5750 - acc: 0.7930 - val_loss: 5.3845 - val_acc: 0.1250\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 13s 4s/step - loss: 0.5996 - acc: 0.8008 - val_loss: 8.0030 - val_acc: 0.0625\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.6781 - acc: 0.7656 - val_loss: 10.0583 - val_acc: 0.0625\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 13s 4s/step - loss: 0.6031 - acc: 0.7910 - val_loss: 8.8986 - val_acc: 0.0625\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 13s 4s/step - loss: 0.5560 - acc: 0.7852 - val_loss: 7.1765 - val_acc: 0.0781\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 13s 4s/step - loss: 0.5658 - acc: 0.8105 - val_loss: 7.2602 - val_acc: 0.0859\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.5728 - acc: 0.7891 - val_loss: 8.3994 - val_acc: 0.0703\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.5483 - acc: 0.8047 - val_loss: 6.8728 - val_acc: 0.1406\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 13s 4s/step - loss: 0.4451 - acc: 0.8477 - val_loss: 7.7583 - val_acc: 0.0859\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 13s 4s/step - loss: 0.4707 - acc: 0.8359 - val_loss: 8.6400 - val_acc: 0.0625\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.4058 - acc: 0.8730 - val_loss: 7.4575 - val_acc: 0.0703\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 15s 4s/step - loss: 0.4115 - acc: 0.8555 - val_loss: 8.0167 - val_acc: 0.0938\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 13s 4s/step - loss: 0.3610 - acc: 0.8906 - val_loss: 7.5197 - val_acc: 0.0703\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.3651 - acc: 0.8750 - val_loss: 7.5657 - val_acc: 0.1016\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 13s 4s/step - loss: 0.3230 - acc: 0.8945 - val_loss: 9.2441 - val_acc: 0.0625\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 13s 4s/step - loss: 0.3275 - acc: 0.8984 - val_loss: 8.5691 - val_acc: 0.0625\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.3787 - acc: 0.8750 - val_loss: 6.7310 - val_acc: 0.0938\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.3680 - acc: 0.8691 - val_loss: 8.1067 - val_acc: 0.0625\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.3955 - acc: 0.8613 - val_loss: 9.7310 - val_acc: 0.0625\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.3235 - acc: 0.8848 - val_loss: 7.4103 - val_acc: 0.0859\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.2561 - acc: 0.9277 - val_loss: 9.0246 - val_acc: 0.0469\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.2607 - acc: 0.9238 - val_loss: 8.0509 - val_acc: 0.0859\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.2445 - acc: 0.9219 - val_loss: 9.2209 - val_acc: 0.0703\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.2338 - acc: 0.9238 - val_loss: 8.4813 - val_acc: 0.0781\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.2383 - acc: 0.9297 - val_loss: 9.3868 - val_acc: 0.0625\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 13s 4s/step - loss: 0.2163 - acc: 0.9355 - val_loss: 9.7152 - val_acc: 0.0703\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.2211 - acc: 0.9277 - val_loss: 9.2611 - val_acc: 0.0625\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.2239 - acc: 0.9316 - val_loss: 5.4610 - val_acc: 0.1484\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.3009 - acc: 0.8848 - val_loss: 10.6367 - val_acc: 0.0625\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.3210 - acc: 0.8848 - val_loss: 11.3439 - val_acc: 0.0469\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.2865 - acc: 0.9023 - val_loss: 5.9708 - val_acc: 0.1406\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.4486 - acc: 0.8594 - val_loss: 7.8406 - val_acc: 0.0781\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.3600 - acc: 0.8613 - val_loss: 9.2899 - val_acc: 0.0547\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.3588 - acc: 0.8730 - val_loss: 6.3438 - val_acc: 0.1094\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.4114 - acc: 0.8750 - val_loss: 8.6428 - val_acc: 0.1250\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.3643 - acc: 0.8770 - val_loss: 5.8464 - val_acc: 0.1328\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 13s 4s/step - loss: 0.3326 - acc: 0.8906 - val_loss: 6.0975 - val_acc: 0.1484\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 13s 4s/step - loss: 0.2822 - acc: 0.9102 - val_loss: 6.7714 - val_acc: 0.1250\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 13s 4s/step - loss: 0.2561 - acc: 0.9180 - val_loss: 6.9394 - val_acc: 0.1016\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.2442 - acc: 0.9160 - val_loss: 5.6668 - val_acc: 0.1484\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.2331 - acc: 0.9141 - val_loss: 6.6781 - val_acc: 0.1172\n",
            "Test loss: 5.993778228759766 / Test accuracy: 0.11874999850988388\n"
          ]
        }
      ],
      "source": [
        "# 定義分類數量\n",
        "num_classes = 50\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(100, 100, 1), activation='relu')) #32 is no. of filters and kernel size is 3*3. ReLU is activation layer\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) #add Max pooling layer with kernel size 2*2 \n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(64, (3, 3), activation='tanh')) \n",
        "model.add(MaxPooling2D(pool_size=(2,2))) \n",
        "model.add(Dropout(0.35))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(256, (3, 3), activation='tanh'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) \n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax')) \n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "model.fit(x_train_r, y_train, validation_data=(x_val_r, y_val), epochs=100, batch_size=200)\n",
        "\n",
        "#Evaluating model in keras\n",
        "score = model.evaluate(x_test_r, y_test, verbose=0)\n",
        "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
        "\n",
        "# model.fit_generator(training_set, epochs = 2, validation_data = test_set, verbose = 1)\n",
        "# score = model.evaluate_generator(test_set)\n",
        "\n",
        "#model.save('my_model.h5', include_optimizer=False)\n",
        "#如果你對這個模型滿意，想要保留之後使用的話，可以這樣設定儲存參數，那麼優化器的狀態不會被保存下來，可以節省不少體積，減少的體積量依使用優化器的不同而定，使用adam的話，這麼做是很有感的，如果你是之前中斷訓練，且有意後續載入繼續進行訓練的話，建議可以先不做。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Structure\n",
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model_{}.png'.format(timestr),show_shapes=True, show_layer_names=True)\n"
      ],
      "metadata": {
        "id": "Wrb8Ksmek-Qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Training History\n",
        "import collections\n",
        "import pandas as pd\n",
        "hist = history.history\n",
        "\n",
        "for key, val in hist.items(): # Count the number of epoch\n",
        "    numepo = len(np.asarray(val))\n",
        "    break\n",
        "hist = collections.OrderedDict(hist)\n",
        "pd.DataFrame(hist).to_excel('model_{}_history.xlsx'.format(timestr), index=True)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig('Model accuracy_{}.png'.format(timestr))\n",
        "plt.cla()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig('Model loss_{}.png'.format(timestr))\n",
        "plt.cla()"
      ],
      "metadata": {
        "id": "x7qDbgi-lHl8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "574df64408e4635801aa20724f5bd67158dcc0405c62728fda99f99539c35838"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}