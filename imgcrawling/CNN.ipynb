{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yewexSls1gmT",
        "outputId": "b41dc290-9ed6-4c7e-a3f8-33dcf2186582"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wiU60mr_z2YS"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder , OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/project/transformation.csv')"
      ],
      "metadata": {
        "id": "XEyTB7c7CCbu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#簡單的\n",
        "x, y = df[df.columns[1:]], df[df.columns[0]]\n",
        "labelencoder = LabelEncoder()\n",
        "y = labelencoder.fit_transform(y)\n",
        "\n",
        "x_traval, x_test, y_traval, y_test = train_test_split(x, y, test_size=0.2, random_state = 1, stratify= y)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_traval, y_traval, test_size=0.2, random_state = 1, stratify= y_traval)\n",
        "\n"
      ],
      "metadata": {
        "id": "5pKugkmGAwrX"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reshape\n",
        "x_train_r = np.array(x_train).reshape(-1,100,100)\n",
        "x_test_r = np.array(x_test).reshape(-1,100,100)\n",
        "x_val_r = np.array(x_val).reshape(-1,100,100)\n",
        "\n",
        "# y_train = np.array(y_train)\n",
        "# y_test = np.array(y_test)\n",
        "# y_val = np.array(y_val)\n",
        "\n",
        "# 轉換色彩 0~255 資料為 0~1\n",
        "x_train_r = x_train_r.astype('float32')\n",
        "x_val_r = x_val_r.astype('float32')\n",
        "x_test_r = x_test_r.astype('float32')\n",
        "\n",
        "x_train_r /= 255\n",
        "x_val_r /= 255\n",
        "x_test_r /= 255\n",
        "\n",
        "# y 值轉成 one-hot encoding\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes=50, dtype='float32') \n",
        "y_test = keras.utils.to_categorical(y_test, num_classes=50, dtype='float32')\n",
        "y_val = keras.utils.to_categorical(y_val, num_classes=50, dtype='float32')\n",
        "\n",
        "# mnist 的圖集黑色是255，白色是 0，而圖片讀進來是 黑色是0，白色是 255\n",
        "# 所以在這裡除255後，也順便把黑白翻轉過來。\n",
        "#data = 1 - data / 255.0 已經做了uint8"
      ],
      "metadata": {
        "id": "j8QFnLNRbnAr"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#標準化 min-max https://stackoverflow.com/questions/72517783/scaling-row-wise-with-minmaxscaler-from-sklearn"
      ],
      "metadata": {
        "id": "564Mp2v08_WW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPZAwY-Qz2Yg"
      },
      "outputs": [],
      "source": [
        "# from keras.preprocessing.image import ImageDataGenerator #利用現有的資料經過旋轉、翻轉、縮放…等方式增加更多的訓練資料\n",
        "# train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
        "# test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "\n",
        "# #要把資料做轉換的步驟則是用 .flow(X,y) 或是 .flow_from_directory(directory) 讀取資料集+批量生成器，產生每epoch訓練樣本\n",
        "# training_set = train_datagen.flow_from_directory(\"./classify/dataset/training_set\", target_size = (64, 64), batch_size = 5)\n",
        "# test_set = test_datagen.flow_from_directory(\"./classify/dataset/test_set\", target_size = (64, 64), batch_size = 5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "sYHmq6WMz2Yi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d9ddd27-be51-431b-ae11-d85908e81dc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "3/3 [==============================] - 9s 3s/step - loss: 3.9546 - acc: 0.0195 - val_loss: 3.9162 - val_acc: 0.0156\n",
            "Epoch 2/20\n",
            "3/3 [==============================] - 9s 3s/step - loss: 3.9117 - acc: 0.0234 - val_loss: 3.9130 - val_acc: 0.0156\n",
            "Epoch 3/20\n",
            "3/3 [==============================] - 9s 3s/step - loss: 3.9065 - acc: 0.0332 - val_loss: 3.9164 - val_acc: 0.0156\n",
            "Epoch 4/20\n",
            "3/3 [==============================] - 9s 3s/step - loss: 3.8974 - acc: 0.0352 - val_loss: 3.9212 - val_acc: 0.0312\n",
            "Epoch 5/20\n",
            "3/3 [==============================] - 10s 3s/step - loss: 3.8758 - acc: 0.0410 - val_loss: 3.9313 - val_acc: 0.0156\n",
            "Epoch 6/20\n",
            "3/3 [==============================] - 9s 3s/step - loss: 3.8405 - acc: 0.0449 - val_loss: 3.9442 - val_acc: 0.0000e+00\n",
            "Epoch 7/20\n",
            "3/3 [==============================] - 9s 3s/step - loss: 3.7709 - acc: 0.0605 - val_loss: 3.9778 - val_acc: 0.0156\n",
            "Epoch 8/20\n",
            "3/3 [==============================] - 9s 3s/step - loss: 3.6656 - acc: 0.0664 - val_loss: 4.0091 - val_acc: 0.0078\n",
            "Epoch 9/20\n",
            "3/3 [==============================] - 9s 3s/step - loss: 3.5388 - acc: 0.1016 - val_loss: 4.0174 - val_acc: 0.0156\n",
            "Epoch 10/20\n",
            "3/3 [==============================] - 9s 3s/step - loss: 3.3648 - acc: 0.1328 - val_loss: 4.0188 - val_acc: 0.0234\n",
            "Epoch 11/20\n",
            "3/3 [==============================] - 9s 3s/step - loss: 3.2024 - acc: 0.1504 - val_loss: 4.0633 - val_acc: 0.0156\n",
            "Epoch 12/20\n",
            "3/3 [==============================] - 9s 3s/step - loss: 2.9988 - acc: 0.2012 - val_loss: 4.0950 - val_acc: 0.0156\n",
            "Epoch 13/20\n",
            "3/3 [==============================] - 9s 3s/step - loss: 2.7798 - acc: 0.2461 - val_loss: 4.1971 - val_acc: 0.0547\n",
            "Epoch 14/20\n",
            "3/3 [==============================] - 9s 3s/step - loss: 2.5650 - acc: 0.2910 - val_loss: 4.3468 - val_acc: 0.0156\n",
            "Epoch 15/20\n",
            "3/3 [==============================] - 9s 3s/step - loss: 2.4494 - acc: 0.3203 - val_loss: 4.2001 - val_acc: 0.0547\n",
            "Epoch 16/20\n",
            "3/3 [==============================] - 9s 3s/step - loss: 2.1600 - acc: 0.3750 - val_loss: 3.9907 - val_acc: 0.0859\n",
            "Epoch 17/20\n",
            "3/3 [==============================] - 9s 3s/step - loss: 1.9158 - acc: 0.4434 - val_loss: 4.3515 - val_acc: 0.0547\n",
            "Epoch 18/20\n",
            "3/3 [==============================] - 9s 3s/step - loss: 1.6812 - acc: 0.5020 - val_loss: 4.4173 - val_acc: 0.0703\n",
            "Epoch 19/20\n",
            "3/3 [==============================] - 9s 3s/step - loss: 1.4942 - acc: 0.5840 - val_loss: 4.4597 - val_acc: 0.0781\n",
            "Epoch 20/20\n",
            "3/3 [==============================] - 9s 3s/step - loss: 1.3225 - acc: 0.6211 - val_loss: 4.5974 - val_acc: 0.0781\n",
            "Test loss: 4.389319896697998 / Test accuracy: 0.08124999701976776\n"
          ]
        }
      ],
      "source": [
        "# 定義分類數量\n",
        "num_classes = 50\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(100, 100, 1), activation='relu')) #32 is no. of filters and kernel size is 5*5. ReLU is activation layer\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) #add Max pooling layer with kernel size 2*2 \n",
        "# model.add(Dropout(0.2))\n",
        "model.add(Conv2D(64, (3, 3), input_shape=(100, 100, 1), activation='relu')) #32 is no. of filters and kernel size is 5*5. ReLU is activation layer\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) #add Max pooling layer with kernel size 2*2 \n",
        "model.add(Conv2D(128, (3, 3), input_shape=(100, 100, 1), activation='relu')) #32 is no. of filters and kernel size is 5*5. ReLU is activation layer\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) #add Max pooling layer with kernel size 2*2 \n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax')) \n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "model.fit(x_train_r, y_train, validation_data=(x_val_r, y_val), epochs=20, batch_size=200)\n",
        "\n",
        "#Evaluating model in keras\n",
        "score = model.evaluate(x_test_r, y_test, verbose=0)\n",
        "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
        "\n",
        "# model.fit_generator(training_set, epochs = 2, validation_data = test_set, verbose = 1)\n",
        "# score = model.evaluate_generator(test_set)\n",
        "\n",
        "\n",
        "#model.save('EfficientNetB0-40-Stripped.h5', include_optimizer=False)如果你對這個模型滿意，想要保留之後使用的話，可以這樣設定儲存參數，那麼優化器的狀態不會被保存下來，可以節省不少體積，減少的體積量依使用優化器的不同而定，使用adam的話，這麼做是很有感的，如果你是之前中斷訓練，且有意後續載入繼續進行訓練的話，建議可以先不做。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "574df64408e4635801aa20724f5bd67158dcc0405c62728fda99f99539c35838"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}